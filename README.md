# ğŸŒŸ Nexus AI â€” ChatGPTâ€‘Style Assistant + Smart Web & Product Scraper

[![Nexus AI](https://img.shields.io/badge/Nexus-AI-6366f1?style=for-the-badge)](#)
![Python](https://img.shields.io/badge/Python-3.10%2B-3776AB?logo=python&logoColor=white&style=for-the-badge)
![Flask](https://img.shields.io/badge/Flask-3.x-000?logo=flask&style=for-the-badge)
![Playwright](https://img.shields.io/badge/Playwright-1.48-2EAD33?logo=playwright&logoColor=white&style=for-the-badge)
![BeautifulSoup](https://img.shields.io/badge/BeautifulSoup4-4.12-2b6cb0?style=for-the-badge)
![Ollama](https://img.shields.io/badge/Ollama-Mistral-00B140?style=for-the-badge)
![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg?style=for-the-badge)

Nexus AI is a fast, privacyâ€‘first AI assistant with a modern ChatGPTâ€‘style UI that blends:
- ğŸ§  Local LLM (Ollama Mistral) for instant offline answers
- ğŸŒ CAPTCHAâ€‘free web search via Playwright + DuckDuckGo
- ğŸ“š Smart prioritization (today, exact dates, Wikipedia ranges)
- ğŸ›’ Product Scraper with Table and Gallery views (images + CSV export)

This README gives you a crystalâ€‘clear overview with diagrams, examples, and simple steps so anyone can get started quickly.

---

## ğŸ§­ Table of Contents

- [Why Nexus AI?](#-why-nexus-ai)
- [Architecture Overview](#-architecture-overview)
- [Quick Start (Oneâ€‘Click)](#-quick-start-oneclick)
- [Manual Setup](#-manual-setup)
- [How It Works (AI Answering Flow)](#-how-it-works-ai-answering-flow)
- [Product Scraper Module](#-product-scraper-module)
- [Project Structure](#-project-structure)
- [Configuration](#-configuration)
- [API Endpoints](#-api-endpoints)
- [Usage Examples](#-usage-examples)
- [Troubleshooting](#-troubleshooting)
- [Performance](#-performance)
- [Contributing, License, Support](#-contributing-license-support)

---

## ğŸ’¡ Why Nexus AI?

- ğŸ”’ Privacy first: your questions run locally whenever possible
- âš¡ Fast: local answers in seconds, web answers in 10â€“20s
- ğŸ§­ Trustworthy: scoring boosts for relevant and recent info
- ğŸ–¼ï¸ Visual scraping: real product images + data in tables
- ğŸ–¥ï¸ Simple start: doubleâ€‘click to run on Windows

Key prioritization (builtâ€‘in):
- ğŸ—“ï¸ Exact Date: +3000
- ğŸ“° Today/Recent: +1000
- ğŸ“š Wikipedia (range like â€œ2003â€“2006â€): +5000 (Supreme)
- ğŸ§Š Old content penalty: âˆ’200 to âˆ’800

---

## ğŸ—ï¸ Architecture Overview

```mermaid
flowchart LR
  U[User ğŸ”µ] --> F[Frontend ğŸ–¥ï¸ (index.html)]
  F -->|POST /ask| B[Flask Backend âš™ï¸ (app.py)]
  B -->|Local query| L[Ollama Mistral ğŸ§ ]
  B -->|If unsure| S[Web Search ğŸŒ (DuckDuckGo via Playwright)]
  S --> R[Result Scorer ğŸ§® (priority logic)]
  L --> A[Answer Builder âœï¸]
  R --> A
  A --> F
  F --> U
```

Modules:
- Frontend (HTML/CSS/JS) with a ChatGPTâ€‘like UI
- Backend (Flask API) orchestrating responses
- Local LLM via Ollama (Mistral)
- Headless/visible Chrome via Playwright for search
- Scoring system for higher accuracy

---

## ğŸš€ Quick Start (Oneâ€‘Click)

Windows recommended

1) Doubleâ€‘click:
- START_NEXUS_AI.bat

What happens automatically:
- âœ… Checks/starts Ollama
- âœ… Starts backend (keep its window open!)
- âœ… Opens the browser UI

If you close the backend window, the UI will show a â€œbackend not runningâ€ error. Just run START_NEXUS_AI.bat again.

---

## ğŸ› ï¸ Manual Setup

First time only:
```bash
# 1) Install Ollama and pull model
# https://ollama.ai
ollama serve
ollama pull mistral

# 2) Install dependencies
pip install -r requirements.txt
# If needed:
# pip install flask flask-cors playwright requests beautifulsoup4
playwright install chrome
```

Run services:
```bash
# Terminal 1: Ollama
ollama serve

# Terminal 2: Backend
python backend/app.py

# Frontend:
# Option A: Open frontend/index.html in a browser
# Option B: Serve locally
cd frontend
python -m http.server 8000
# Visit http://localhost:8000
```

Health check:
```bash
curl http://localhost:5000/health
```

---

## ğŸ§  How It Works (AI Answering Flow)

```mermaid
sequenceDiagram
  autonumber
  participant U as User
  participant FE as Frontend
  participant BE as Backend (Flask)
  participant LL as Local LLM (Ollama Mistral)
  participant WS as Web Search (Playwright/DDG)

  U->>FE: Ask a question
  FE->>BE: POST /ask {question}
  BE->>LL: Try local answer
  alt Confident
    LL-->>BE: Local answer
  else Not confident
    BE->>WS: Run search (DuckDuckGo)
    WS-->>BE: Search results
    BE->>BE: Apply priority scoring (date, today, wikipedia)
  end
  BE-->>FE: Answer + sources + method
  FE-->>U: Render response with badges
```

Scoring tiers:
- â­â­â­â­â­ +5000: Wikipedia + Historical range (e.g., â€œ2003â€“2006â€)
- â­â­â­ +3000: Exact date match (e.g., â€œOct 10, 2025â€)
- â­â­ +1000: Today/Recent info
- â­ +500: Wikipedia general
- âš–ï¸ 0: Standard results
- ğŸš« âˆ’200 to âˆ’800: Old content penalty

---

## ğŸ›’ Product Scraper Module

Scrape search results into structured JSON, display as Cards, Table, or Gallery with real images.

Open the views (after backend is running):
- JSON Cards: http://localhost:5000/scraper.html
- Table & Gallery: http://localhost:5000/table_view.html

Features:
- ğŸ“¦ Batch processing (configurable, default 5)
- ğŸ§¹ Clean metadata extraction (title, price, specs, rating)
- ğŸ–¼ï¸ 4â€“5 images per product in Gallery view
- ğŸ“¤ Export CSV in Table view

Highâ€‘level flow:
```mermaid
flowchart TD
  UI[Scraper UI ğŸ”] -->|POST /scrape_products| API(Flask API)
  API --> SR[Search Results (DDG/Bing Fallback)]
  SR --> WB[Web Scraper (requests + BeautifulSoup)]
  WB -->|Batches| FS[(agent_state/*.json)]
  FS --> UI
  subgraph Frontend
    UI --> TableView[Table View ğŸ“Š]
    UI --> GalleryView[Gallery View ğŸ–¼ï¸]
    UI --> Cards[JSON Cards ğŸ§¾]
  end
```

Typical query:
- â€œtop 20 laptops under 60000â€
- Limit: 20, Batch size: 5 â†’ 4 JSON batch files saved to agent_state/

---

## ğŸ“ Project Structure

```
Nexus-App/
â”œâ”€ backend/
â”‚  â”œâ”€ app.py                # Flask API server
â”‚  â”œâ”€ agent_step3.py        # Core agent + search/scoring logic
â”‚  â””â”€ agent_state/          # Saved scrape batches, state files
â”œâ”€ frontend/
â”‚  â”œâ”€ index.html            # Main chat interface
â”‚  â”œâ”€ styles.css            # Styling
â”‚  â””â”€ script.js             # Frontend logic
â”œâ”€ table_view.html          # Table + Gallery UI (served by backend if configured)
â”œâ”€ *.bat / *.ps1            # One-click starters and helpers (Windows)
â”œâ”€ requirements.txt         # Python deps
â””â”€ README.md                # This file
```

Tip: Keep the backend window open while using the app.

---

## âš™ï¸ Configuration

Frontend API endpoint (in JS):
```javascript
// frontend/script.js
const API_URL = 'http://localhost:5000';
```

Ollama / Model settings (Python):
```python
# backend/agent_step3.py
OLLAMA_API = "http://127.0.0.1:11434/api/generate"
MODEL_NAME = "mistral"
channel = "chrome"  # or "msedge"
headless = false    # true = headless mode
```

Change backend port (if 5000 is busy):
```python
# backend/app.py
app.run(host="0.0.0.0", port=5001)
```
And match in frontend:
```javascript
const API_URL = 'http://localhost:5001';
```

---

## ğŸ”Œ API Endpoints

Core
- GET /health â†’ {"status":"ok","message":"Nexus AI Backend is running"}
- POST /ask â†’ { question: string } â†’ { answer, method: "local"|"web", sources: [] }
- POST /shutdown â†’ Graceful shutdown

Product Scraper
- POST /scrape_products
  - Body: { "query": "top 20 laptops under 60000", "limit": 20, "batch_size": 5 }
  - Returns: { success, total_items, total_batches, batches: [...] }
  - Saves: agent_state/scrape_batch_*.json

---

## ğŸ§ª Usage Examples

Todayâ€™s info
```
â“ What's the weather today in Hyderabad?
âœ… Boosted by +1000 (recent/today)
```

Exact date
```
â“ What's happening on October 10, 2025?
âœ… +3000 exact date match ğŸ“…
```

Historical range
```
â“ What happened between 2003 and 2006?
âœ… Wikipedia prioritized with +5000 ğŸ”
```

General knowledge
```
â“ How does photosynthesis work?
ğŸ¤– Mistral answers locally (fast & private)
```

Scraper (UI)
- Open table_view.html â†’ search â€œtop 20 laptops under 60000â€ â†’ switch Table/Gallery â†’ Export CSV

---

## ğŸ§© Troubleshooting

Backend wonâ€™t start
- Check port 5000 is free
- pip install -r requirements.txt
- Start Ollama: ollama serve

Frontend canâ€™t connect
- Verify API_URL in frontend/script.js
- Make sure backend window is open and shows â€œRunning on http://localhost:5000â€

Chrome wonâ€™t open
- playwright install chrome
- Or set channel="msedge"

CAPTCHA shows up
- Ensure DuckDuckGo is used (not Google/Bing)
- Try headless=true or private window

Port already in use
- Change Flask to 5001 (see Configuration)
- Update API_URL accordingly

System check
```bash
python test_setup.py
```

---

## ğŸ“ˆ Performance

- Local LLM: ~3â€“5s
- Web search: ~10â€“20s (query dependent)
- Memory (with browser): ~500MB
- Concurrent requests: supported

---

## ğŸ¤ Contributing, License, Support

Contributing
1. Fork this repo
2. Create a feature branch
3. Make changes + add tests if applicable
4. Open a pull request

License
- MIT â€” free to use and modify

Support
- Open an issue if something isnâ€™t working
- Health: http://localhost:5000/health
- Quick docs: START_HERE.md, USAGE_GUIDE.md

---

## ğŸ“· (Optional) Screenshots & Diagrams

Place your images here and reference them in this README:
- docs/images/home.png
- docs/images/table.png
- docs/images/gallery.png

Example:
```md
![Table View](docs/images/table.png)
```

---

Made with â¤ï¸ for intelligent, privacyâ€‘focused AI assistance
